{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical and Consistent Estimation of $f$-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (21.1.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: cvxpy in /usr/local/lib/python3.6/dist-packages (1.1.12)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from cvxpy) (1.19.5)\n",
      "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy) (2.0.7.post1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from cvxpy) (1.5.4)\n",
      "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from cvxpy) (2.1.3)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy) (0.6.2.post0)\n",
      "Requirement already satisfied: qdldl in /usr/local/lib/python3.6/dist-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.6.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (0.1.6)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.19.5)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (0.3.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.15.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (4.4.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install cvxpy\n",
    "!pip install seaborn\n",
    "!pip install --upgrade tensorflow-probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.4.1\n",
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import time\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import h5py\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'sans-serif', 'sans-serif':['Helvetica']})\n",
    "rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Squared Hellinger divergence:\n",
    "\n",
    "    $H^2(P, Q) = \\int \\Bigl(\\sqrt{p(z)} - \\sqrt{q(z)}\\Bigr)^2 dz$\n",
    "- $\\chi^2$-divergence:\n",
    "    \n",
    "    $\\chi^2(P, Q) = \\int \\log \\Bigl(p(z) / q(z)\\Bigr)^2 q(z) dz - 1$.\n",
    "- KL-divergence:\n",
    "\n",
    "    $KL(Q, P) = \\int \\log \\Bigl(q(z) / p(z)\\Bigr) q(z) dz$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-Form Divergence Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dims(A):\n",
    "    \"\"\"Gets input and latent dimensions from matrix (tensor) A.\n",
    "    \n",
    "    Input dimension: #columns.\n",
    "    Latent dimension: #rows.\n",
    "    \n",
    "    Args:\n",
    "        A: Parameter matrix.\n",
    "    Returns:\n",
    "        dim_latent, dim_input: A tuple containing lists representing the row and column\n",
    "                                dimensions of the parameter matrix A.\n",
    "    \"\"\"\n",
    "    dim_latent, dim_input = A.get_shape().as_list()\n",
    "    \n",
    "    return dim_latent, dim_input\n",
    "\n",
    "def get_cov(A, std):\n",
    "    \"\"\"Constructs the covariance matrix with given matrix and standard deviation.\n",
    "    \n",
    "    Args:\n",
    "        A: Parameter matrix determining the covariance matrix.\n",
    "    Returns:\n",
    "        cov: A tf tensor representing the constructed covariance matrix.\n",
    "        \n",
    "    \"\"\"\n",
    "    dim_latent, _ = get_dims(A)\n",
    "    cov = tf.matmul(A, A, transpose_b=True) + std**2 * tf.eye(dim_latent)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl(A, b, std):\n",
    "    \"\"\"Compute the KL-divergence between baseline distribution Pz and distribution Qz.\n",
    "    \n",
    "    Here the baseline distribution Pz is a unit Multivariate Normal distribution with\n",
    "    mean zero and diag(1) covariance. The distribution Qz is a Multivariate Normal\n",
    "    distribution with mean b and covariance AA^t + (std**2)I.\n",
    "    \n",
    "    Args:\n",
    "        A: Parameter matrix determining covariance matrix of Qz.\n",
    "        b: Mean of Qz.\n",
    "        std: Standard deviation parameter determining covariance matrix of Qz.\n",
    "    Returns:\n",
    "        kl_divergence: A numpy array of computed KL-divergence.\n",
    "    \"\"\"\n",
    "    dim_latent, _ = get_dims(A)\n",
    "    # Create a Multivariate Normal distribution with a diagonal covariance and mean 0.\n",
    "    # The Multivariate Normal distribution is defined over R^k and parameterized by a\n",
    "    # length-k loc vector (aka 'mu') and a k x k scale matrix; Note that the covariance\n",
    "    # is given by covariance = scale @ scale.T, where @ denotes matrix multiplication\n",
    "    p = tfd.MultivariateNormalDiag(loc=tf.zeros(shape=(dim_latent,)),\n",
    "                                 scale_diag=tf.ones(dim_latent))\n",
    "    q_cov = get_cov(A, std)\n",
    "    q = tfd.MultivariateNormalTriL(loc=b, scale_tril=q_cov)\n",
    "    kl_divergence = q.kl_divergence(p).numpy()\n",
    "    \n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ram_mc(n, m, A, b, std, f, num_iters):\n",
    "    \"\"\"Estimates Df(Qz, Pz) with RAM-MC estimator where Pz is a unit Gaussian and Qz\n",
    "    is a Gaussian with mean b and covariance AA^t + (std**2)I.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of mixture components to approximate Qz.\n",
    "        m: Number of MC samples to use.\n",
    "        A: Parameter determining covariance matrix of Qz.\n",
    "        b: Mean of Qz.\n",
    "        std: Standard deviation parameter determining covariance matrix of Qz.\n",
    "        f: A string representing the f-divergence type, now \"KL\" only.\n",
    "        num_iters: Number of iterations to perform.\n",
    "    Returns:\n",
    "        estimates: A numpy array of estimates, one per num_iter.\n",
    "    \"\"\"\n",
    "    dim_latent, dim_input = get_dims(A)\n",
    "    p = tfd.MultivariateNormalDiag(loc=tf.zeros(shape=(dim_latent,)),\n",
    "                                 scale_diag=tf.ones(dim_latent))\n",
    "    # Base P(X) distribution, which is a standard normal in d_input.\n",
    "    p_base = tfd.MultivariateNormalDiag(loc=tf.zeros(shape=(dim_input,)),\n",
    "                                 scale_diag=tf.ones(dim_input))\n",
    "    \n",
    "    p_base_samples = p_base.sample(n * num_iters) # Minibatch samples from P(X).\n",
    "    p_base_samples = tf.reshape(p_base_samples, [num_iters, n, dim_input])\n",
    "    A = tf.reshape(A, [1, dim_latent, dim_input])\n",
    "    # Create a new tensor by replicating A num_iters times.\n",
    "    A = tf.tile(A, [num_iters, 1, 1])\n",
    "    p_base_posterior = tfd.MultivariateNormalDiag(\n",
    "        loc=tf.matmul(p_base_samples, A, transpose_b=True) + b,\n",
    "        scale_diag=std * tf.ones(dim_latent)\n",
    "    )\n",
    "    # Compute a mixture distribution. Experiment-specific parameters are indexed with\n",
    "    # the first dimension (num_iters) in p_base_posterior.\n",
    "    mixture = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=[1. / n] * n),\n",
    "        components_distribution=p_base_posterior\n",
    "    )\n",
    "    if f == 'KL':\n",
    "        mc_samples = mixture.sample(m)\n",
    "        log_density_ratios = mixture.log_prob(mc_samples) - p.log_prob(mc_samples)\n",
    "        estimates = (tf.reduce_mean(log_density_ratios, axis=0)).numpy()\n",
    "    else:\n",
    "        raise ValueError(\"f must be one of 'KL'.\")\n",
    "    \n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_plugin(n, m, A, b, std, f, num_iters, eps=1e-8):\n",
    "    \"\"\"Estimates Df(Qz, Pz) with the plugin estimator. Pz is the unit Gaussian and Qz is\n",
    "    Gaussian with mean b and covariance AA^t +(std**2)I. First perform kernel density\n",
    "    estimation of two densities, then plug in.\n",
    "    \"\"\"\n",
    "    def numpy_sample(p, n, d):\n",
    "        points = p.sample(n)\n",
    "        points = tf.reshape(points, [d, -1]).numpy()\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    dim_latent, dim_input = get_dims(A)\n",
    "    p = tfd.MultivariateNormalDiag(loc=tf.zeros(shape=(dim_latent,)),\n",
    "                                 scale_diag=tf.ones(dim_latent))\n",
    "    q_cov = get_cov(A, std)\n",
    "    q = tfd.MultivariateNormalTriL(loc=b, scale_tril=q_cov)\n",
    "#     q = tfd.MultivariateNormalTriL(loc=b, scale_tril=tf.linalg.cholesky(q_cov))\n",
    "\n",
    "    \n",
    "    # Repeat experiments for num_iters iterations.\n",
    "    results = []\n",
    "    for experiment in range(num_iters):\n",
    "        # Get i.i.d. samples from p and q to perform kernel density estimations.\n",
    "        p_kde_points = numpy_sample(p, n, dim_latent)\n",
    "        q_kde_points = numpy_sample(q, n, dim_latent)\n",
    "    \n",
    "        try:\n",
    "            p_hat = stats.gaussian_kde(p_kde_points)\n",
    "            q_kde_points = stats.gaussian_kde(q_kde_points)\n",
    "        except:\n",
    "            results.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        mc_points = numpy_sample(q, m, dim_latent)\n",
    "        try:\n",
    "            q_vals = q_hat.evaluate(mc_points)\n",
    "            p_vals = p_hat.evaluate(mc_points) + eps\n",
    "            log_q_vals = q_hat.logpdf(mc_points)\n",
    "            log_p_vals = p_hat.logpdf(mc_points) + eps\n",
    "        except:\n",
    "            results.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        if f == 'KL':\n",
    "            results.append(np.mean(log_q_vals - log_p_vals))\n",
    "        else:\n",
    "            raise ValueError(\"f must be one of 'KL'.\")\n",
    "    \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments and make plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RANGE = [1, 500] # Sample sizes\n",
    "MC_NUM = 128 # Number of Monte-Carlo samples for RAM-MC\n",
    "N_EXP = 10 # Number of iterations to repeat each experiment\n",
    "K = 20 # Base space dimensionality.\n",
    "STD = 0.5 # Gaussian covariance noise.\n",
    "BETA = 0.5 # Scale for base covariance.\n",
    "D_RANGE = [1, 4, 16] # Latent space dimensionality.\n",
    "LBD_MAX = 2. # Lambda range.\n",
    "ROOT_PATH = '/Data/'\n",
    "\n",
    "tf.random.set_seed(345)\n",
    "\n",
    "# Generating A and b parameters for various dimensions.\n",
    "BASE_PARAMS = {}\n",
    "for d in D_RANGE:\n",
    "    b0 = tf.random.normal(shape=(d,))\n",
    "    b0 /= np.linalg.norm(b0)\n",
    "    A0 = tf.random.normal(shape=(d, K))\n",
    "    A0 /= tf.linalg.norm(A0)\n",
    "    BASE_PARAMS[d] = {'b0': b0, 'A0': A0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 500\n",
      "4 1\n",
      "4 500\n",
      "16 1\n",
      "16 500\n"
     ]
    }
   ],
   "source": [
    "RUN_RAM_MC_PLUGIN_EXPERIMENTS = True\n",
    "\n",
    "def load_figure1_data(file_name):\n",
    "    data = {}\n",
    "    path = os.path.join(ROOT_PATH, file_name)\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        for i in f:\n",
    "            data[int(i)] = {}\n",
    "            for j in f[i]:\n",
    "                data[int(i)][int(j)] = {}\n",
    "                for k in f[i][j]:\n",
    "                    data[int(i)][int(j)][k] = list(f[i][j][k])\n",
    "    return data\n",
    "\n",
    "if RUN_RAM_MC_PLUGIN_EXPERIMENTS:\n",
    "    ram_mc_plugin_results = {}\n",
    "    for d in D_RANGE:\n",
    "        if d not in ram_mc_plugin_results:\n",
    "            ram_mc_plugin_results[d] = {}\n",
    "        for n in N_RANGE:\n",
    "            print(d, n)\n",
    "            if n not in ram_mc_plugin_results[d]:\n",
    "                ram_mc_plugin_results[d][n] = {}\n",
    "            for lbd in np.linspace(-LBD_MAX, LBD_MAX, 51):\n",
    "                # Create Abase with ones on diagonal\n",
    "                Abase = np.zeros((d, K))\n",
    "                np.fill_diagonal(Abase, 1.)\n",
    "                Abase = tf.convert_to_tensor(Abase, tf.dtypes.float32)\n",
    "                Albd = Abase * BETA + lbd * BASE_PARAMS[d]['A0']\n",
    "                blbd = lbd * BASE_PARAMS[d]['b0']\n",
    "\n",
    "                # Compute true closed form values (only once)\n",
    "                if n == N_RANGE[0]:\n",
    "                    true_kl = compute_kl(Albd, blbd, STD)\n",
    "                    true_hsq = None\n",
    "                    true_chi2 = None\n",
    "                else:\n",
    "                    true_kl = None\n",
    "\n",
    "                for dvg in ['KL']:\n",
    "                    if dvg not in ram_mc_plugin_results[d][n]:\n",
    "                        ram_mc_plugin_results[d][n][dvg] = []\n",
    "                        \n",
    "                        batch_ram_mc = compute_ram_mc(n, MC_NUM, Albd, blbd, STD,\n",
    "                                                      f=dvg, num_iters=N_EXP)\n",
    "                        \n",
    "                        batch_plugin = estimate_plugin(n, MC_NUM, Albd, blbd, STD,\n",
    "                                                       f=dvg, num_iters=N_EXP)\n",
    "                        \n",
    "                        ram_mc_plugin_results[d][n][dvg].append(\n",
    "                            (true_kl, true_hsq, true_chi2, batch_ram_mc, batch_plugin))\n",
    "else:\n",
    "    ram_mc_plugin_results = load_figure1_data('ram_mc_plugin_results.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nguyen_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2adff714eca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mmake_plot_figure1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mram_mc_plugin_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnguyen_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nguyen_results' is not defined"
     ]
    }
   ],
   "source": [
    "#@title Generate plots { display-mode: \"form\" }\n",
    "\n",
    "def make_plot_figure1(ram_mc_plugin_results, nguyen_results):\n",
    "  sns.set_style(\"white\")\n",
    "  fig = plt.figure(figsize = (13, 8))\n",
    "  elinewidth = 0.4  # Width of errorbars\n",
    "  errorevery = 3  # Set spacing of error bars to avoid crowding of figure.\n",
    "\n",
    "  def overflow_std(array):\n",
    "    \"\"\"Calculates std of array, but if overflow error would occur returns a \n",
    "    finite number larger than the range of any axes used in plots.\"\"\"\n",
    "    if (np.inf in array) or (np.nan in array) or any(1e20 < array):\n",
    "      std = 1e20\n",
    "    else:\n",
    "      std = np.std(array)\n",
    "    return std\n",
    "\n",
    "  for i in range(1, 10):\n",
    "    sp = plt.subplot(3, 3, i)\n",
    "    d = D_RANGE[(i - 1) % 3]\n",
    "    dvg = ['KL', 'Chi2', 'Hsq'][int((i - 1) / 3)]\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(N_RANGE)))\n",
    "    for color, n in zip(colors, N_RANGE):\n",
    "\n",
    "      if n == N_RANGE[0]:\n",
    "        # Plot true values\n",
    "        idx = N_RANGE[0]\n",
    "        true_kl = np.array([el[0] for el in ram_mc_plugin_results[d][idx][dvg]])\n",
    "        true_hsq = np.array(\n",
    "            [el[1] for el in ram_mc_plugin_results[d][idx][dvg]])\n",
    "        true_chi2 = np.array([el[2] if isinstance(el[2], float) else el[2]\n",
    "                              for el in ram_mc_plugin_results[d][idx][dvg]])\n",
    "        if dvg == 'KL':\n",
    "          plt.plot(true_kl, color='blue', linewidth=3, label='Truth')\n",
    "          plt.yscale('log')\n",
    "        if dvg == 'Hsq':\n",
    "          plt.plot(true_hsq, color='blue', linewidth=3, label='Truth')\n",
    "        if dvg == 'Chi2':\n",
    "          plt.plot(true_chi2, color='blue', linewidth=3, label='Truth')\n",
    "          plt.yscale('log')\n",
    "\n",
    "      # Plot RAM-MC estimates for N=500.\n",
    "      if n == 500:\n",
    "        mean_ram_mc_n500 = np.array(\n",
    "            [np.mean(el[3]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        std_ram_mc_n500 = np.array(\n",
    "            [np.std(el[3]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        color = 'red'\n",
    "        plt.errorbar(range(51),\n",
    "                    mean_ram_mc_n500,\n",
    "                    errorevery=errorevery,\n",
    "                    yerr=std_ram_mc_n500,\n",
    "                    elinewidth=elinewidth,\n",
    "                    color=color, label='RAM-MC estimator, N=' + str(n),\n",
    "                    marker=\"^\", markersize=5, markevery=10)\n",
    "\n",
    "      # Plot Nguyen estimates\n",
    "      if n == 500 and dvg == 'KL':\n",
    "        color = 'green'\n",
    "        mean_nguyen = np.array(\n",
    "            [np.mean(el) for el in nguyen_results[d][n][dvg]])\n",
    "        std_nguyen = np.array(\n",
    "            [np.std(el) for el in nguyen_results[d][n][dvg]])\n",
    "        plt.errorbar(range(51),\n",
    "                    mean_nguyen,\n",
    "                    errorevery=errorevery,\n",
    "                    yerr=std_nguyen,\n",
    "                    elinewidth=elinewidth,\n",
    "                    color=color, label='M1 estimator, N=' + str(n),\n",
    "                    marker=\"v\", markersize=5, markevery=10)\n",
    "\n",
    "      # Plot plug-in estimates\n",
    "      if n == 500:\n",
    "        mean_plugin = np.array(\n",
    "            [np.mean(el[4]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        std_plugin = np.array(\n",
    "            [overflow_std(el[4]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        color = 'darkorange'\n",
    "        plt.errorbar(range(51),\n",
    "                    mean_plugin,\n",
    "                    errorevery=errorevery,\n",
    "                    yerr=std_plugin,\n",
    "                    elinewidth=elinewidth,\n",
    "                    color=color, label='Plug-in estimator, N=' + str(n),\n",
    "                    marker=\"s\", markersize=5, markevery=10)\n",
    "\n",
    "      # Plot RAM-MC with N=1.\n",
    "      if n == N_RANGE[0]:\n",
    "        color = 'black'\n",
    "        mean_ram_mc1 = np.array(\n",
    "            [np.mean(el[3]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        std_ram_mc1 = np.array(\n",
    "            [np.std(el[3]) for el in ram_mc_plugin_results[d][n][dvg]])\n",
    "        plt.errorbar(range(51) + 0.3 * np.ones(51),\n",
    "                    mean_ram_mc1,\n",
    "                    errorevery=errorevery,\n",
    "                    yerr=std_ram_mc1,\n",
    "                    elinewidth=elinewidth,\n",
    "                    color=color, label='RAM-MC estimator, N=1',\n",
    "                    marker=\"o\", markersize=5, markevery=10)\n",
    "\n",
    "      if dvg == 'KL':\n",
    "        plt.ylim((0.03, 15))\n",
    "      if dvg == 'Chi2':\n",
    "        plt.ylim((0.1, 1e6))\n",
    "      if dvg == 'Hsq':\n",
    "        plt.ylim((0., 2))\n",
    "\n",
    "    sp.axes.get_xaxis().set_ticklabels([])\n",
    "    if d != 1:\n",
    "      sp.axes.get_yaxis().set_ticklabels([])\n",
    "    else:\n",
    "      sp.axes.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "    if i < 4:\n",
    "      plt.title(\"d = {}\".format(d), fontsize=18)\n",
    "    if i == 1:\n",
    "      plt.ylabel('KL', fontsize=18)\n",
    "    if i == 4:\n",
    "      plt.ylabel(r'$\\chi^2$', fontsize=18)\n",
    "    if i == 7:\n",
    "      plt.ylabel(r'$H^2$', fontsize=18)\n",
    "\n",
    "\n",
    "    # Hide the right and top spines.\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines.\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    plt.tick_params(\n",
    "      axis='x',          # changes apply to the x-axis\n",
    "      which='both',      # both major and minor ticks are affected\n",
    "      bottom=False,      # ticks along the bottom edge are off\n",
    "      top=False,         # ticks along the top edge are off\n",
    "      labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.tick_params(\n",
    "      axis='y',          # changes apply to the x-axis\n",
    "      which='both',      # both major and minor ticks are affected\n",
    "      left=False,      # ticks along the bottom edge are off\n",
    "      right=False,         # ticks along the top edge are off\n",
    "      labelbottom=False) # labels along the bottom edge are off\n",
    "    ax.yaxis.grid()\n",
    "    plt.xlim((-2, 51))\n",
    "\n",
    "    if i > 6:\n",
    "      plt.xlabel(r\"$\\lambda$\", fontsize=17)\n",
    "\n",
    "  ax = fig.axes[1]\n",
    "  handles, labels = ax.get_legend_handles_labels()\n",
    "  labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "  fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.51, 1.0),\n",
    "            ncol=5, fancybox=True, shadow=True, fontsize=12, frameon=True)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "make_plot_figure1(ram_mc_plugin_results, nguyen_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
